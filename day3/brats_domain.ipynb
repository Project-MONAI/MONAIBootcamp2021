{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain shift regression\n",
    "\n",
    "This notebook is a brief template to generate synthetic gadolinium-enhanced T1w brain image from FLAIR, T1w and T2w images.\n",
    "\n",
    "For the sake of speed, a 2D dataset has been created by taking slices from the 3D BRATS brain tumor dataset.\n",
    "\n",
    "The dataset comes from http://medicaldecathlon.com/.  \n",
    "\n",
    "A number of blanks need to be filled in to get some results, and then improvements can be made to improve upon these!\n",
    "\n",
    "## Todo\n",
    "* Decide upon a network, loss function, optimzer, etc.\n",
    "* Add a validation section\n",
    "\n",
    "## Improvements\n",
    "Can you use any techniques to improve upon results or accelerate the training (e.g., AMP)?\n",
    "\n",
    "## Extension\n",
    "Can you get reasonable results once certain channels from the input (e.g., the T2w) have been removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -qU \"monai[ignite, nibabel, torchvision, tqdm, gdown]==0.6.0\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import trange\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import Dataset, DataLoader, partition_dataset\n",
    "from monai.networks import eval_mode\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureTyped,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    rescale_array,\n",
    "    ScaleIntensityd,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()\n",
    "set_determinism(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_dir, \"brain_2d\")\n",
    "resource = \"https://drive.google.com/uc?id=17f4J_rU5pi1zRmxMe5OwljyT3tlBf6qI\"\n",
    "compressed_file = os.path.join(root_dir, \"brain_2d.tar.gz\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ims = sorted(glob(os.path.join(data_dir, \"*input.npy\")))\n",
    "output_ims = sorted(glob(os.path.join(data_dir, \"*GT_output.npy\")))\n",
    "data = [{\"input\": i, \"output\": o} for i, o in zip(input_ims, output_ims)]\n",
    "print(\"number data points\", len(data))\n",
    "print(\"example\", data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelWiseScaleIntensityd(MapTransform):\n",
    "    \"\"\"Perform channel-wise intensity normalisation.\"\"\"\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "    def __call__(self, d):\n",
    "        for key in self.keys:\n",
    "            for idx, channel in enumerate(d[key]):\n",
    "                d[key][idx] = rescale_array(channel)\n",
    "        return d\n",
    "\n",
    "keys = [\"input\", \"output\"]\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys),\n",
    "    ChannelWiseScaleIntensityd(\"input\"),\n",
    "    ScaleIntensityd(\"output\"),\n",
    "    EnsureTyped(keys),\n",
    "])\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys),\n",
    "    ChannelWiseScaleIntensityd(\"input\"),\n",
    "    ScaleIntensityd(\"output\"),\n",
    "    EnsureTyped(keys),\n",
    "])\n",
    "\n",
    "t = train_transforms(data[0])\n",
    "print(t[\"input\"].shape, t[\"output\"].shape)\n",
    "in_channels, out_channels = t[\"input\"].shape[0], t[\"output\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 80% and 20% for training and validation, respectively\n",
    "train_data, val_data = partition_dataset(data, (8, 2), shuffle=True)\n",
    "print(\"num train data points:\", len(train_data))\n",
    "print(\"num val data points:\", len(val_data))\n",
    "batch_size = 10\n",
    "num_workers = 10\n",
    "train_ds = Dataset(train_data, train_transforms)\n",
    "train_dl = DataLoader(train_ds, num_workers=num_workers, batch_size=batch_size, shuffle=True)\n",
    "val_ds = Dataset(val_data, val_transforms)\n",
    "val_dl = DataLoader(val_ds, num_workers=num_workers, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create loss fn and optimiser\n",
    "max_epochs = None  # TODO\n",
    "model = None  # TODO\n",
    "loss_function = None  # TODO\n",
    "optimizer = None  # TODO\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "t = trange(max_epochs, desc=f\"epoch 0, avg loss: inf\", leave=True)\n",
    "for epoch in t:\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch in train_dl:\n",
    "        step += 1\n",
    "        inputs, outputs_gt = batch[\"input\"].to(device), batch[\"output\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, outputs_gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= step\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    t.set_description(f\"epoch {epoch + 1}, average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def imshows(ims):\n",
    "    \"\"\"Visualises a list of dictionaries.\n",
    "\n",
    "    Each key of the dictionary will be used as a column, and\n",
    "    each element of the list will be a row.\n",
    "    \"\"\"\n",
    "    nrow = len(ims)\n",
    "    ncol = len(ims[0])\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(\n",
    "        ncol * 3, nrow * 3), facecolor='white')\n",
    "    for i, im_dict in enumerate(ims):\n",
    "        for j, (title, im) in enumerate(im_dict.items()):\n",
    "            if isinstance(im, torch.Tensor):\n",
    "                im = im.detach().cpu().numpy()\n",
    "            # If RGB, put to end. Else, average across channel dim\n",
    "            if im.ndim > 2:\n",
    "                im = np.moveaxis(im, 0, -1) if im.shape[0] == 3 else np.mean(im, axis=0)\n",
    "\n",
    "            ax = axes[j] if len(ims) == 1 else axes[i, j]\n",
    "            ax.set_title(f\"{title}\\n{im.shape}\")\n",
    "            im_show = ax.imshow(im)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "to_imshow = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()\n",
    "\n",
    "for idx in np.random.choice(len(val_ds), size=5, replace=False):\n",
    "    rand_data = val_ds[idx]\n",
    "    rand_input, rand_output_gt = rand_data[\"input\"], rand_data[\"output\"]\n",
    "    rand_output = model(rand_input.to(device)[None])[0]\n",
    "    to_imshow.append(\n",
    "        {\n",
    "            \"FLAIR\": rand_input[0],\n",
    "            \"T1w\": rand_input[1],\n",
    "            \"T2w\": rand_input[2],\n",
    "            \"GT GD\": rand_output_gt,\n",
    "            \"inferred GD\": rand_output,\n",
    "        }\n",
    "    )\n",
    "imshows(to_imshow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
